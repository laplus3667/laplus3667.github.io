[{"categories":["寫作"],"content":"清單體的四個角度  紫式晦澀每日一篇文章第7天\n  前言   今天是2022年第5天, 第1週的第1個週三. 今天來整理之前對「清單體」話題的一些筆記.\n  今天的素材主要是從得到APP與網路上收集而來. 從五個訊息源頭做了15個點的筆記. 以下整理為關於清單體的五個角度.\n  結構寫作:快速起承轉合, 體裁骨架, 題材血肉, 提高閱讀便利性 結構化寫作文體:   要想學會快速寫文章，需要掌握一些「易於複製、條理清晰的結構化寫作文體」。 比如日記體、清單體、語錄體、點評體、問答體等。 這些文體最大的優點是幫助寫作者快速搞定文章結構，快速起承轉合，把思想的「血肉」迅速填充到文章的「骨架」當中。  體裁骨架, 題材血肉:   寫文章，首先需要搞定「體裁（文體）」和「題材」的區別。 體裁是文章的種類和樣式，側重形式特徵；題材是文章涉及的領域、話題或素材，側重內容特徵。 文章的體裁，也稱文體，用於解決「用什麼文章形式」「怎麼寫」的問題；題材用於解決「關注什麼話題」「寫什麼」的問題。 掌握結構化的快捷文體，能夠幫我們快速整理思路、鋪陳素材、流暢表達，寫作效率可以明顯提高，也更容易養成持續寫作的習慣。  前結構化寫作:   常見的結構化寫作文體：日記體、清單體、語錄體、資訊體、點評體、圖片體、問答體、倒金字塔體等等。 前結構化寫作最大的功用，是可以幫助寫作者快速解決「文章如何鋪陳」「先寫什麼後寫什麼」「怎麼快速下筆」的問題，鼓勵作者先把文章寫出來，而不必過多糾結於文章怎麼起承轉合。 此外，結構化寫作還有這些優勢：降低理解成本、提高閱讀便利性、易於分享和傳播。  知識分享: 個人喜好排序, 品味清單體, 高級整理者 清單依喜好排序萬事萬物:   一切有邏輯關係的事物都可以用列表的方式來呈現。 我們列清單，是因為萬事萬物開始圍繞著我們的需求喜好來重新排序，而不再受傳統的層級類型的限制。 清單可以做什麼？既可以是個人邏輯梳理的工具，也可以作為結構化社會知識的載體。  清單體（listicle）高度可分享:   內容的清單化：無清單，不傳播 內容的清單化早在產品的清單化之前就已經開始了。 《紐約時報》內部去年5月發佈一份《數字時代革新報告》，其中將BuzzFeed的成名原因總結為3點：積極進取的社交網絡推廣、高度可分享的內容、試驗性的新聞模式。 清單體（listicle）與小測試、短視頻一起，正好構成其高度可分享的、試驗性等3大特色  先做一個高級的整理者:   清單體沒有作者，而只有編輯。或者說，作者的角色降級為「整理者」，很多微信公眾賬號的運營者扮演的正是這樣的角色。 早在2013年，鈦媒體作者魏武揮老師就指出：一個平台活躍度的核心，生產者並不是第一位重要的，整理者才是第一位重要的。 先是高級的整理者，才有辦法同中有異，創新。  知識輸出: 快速輸出精華, 一段三行強操作性, 以編輯鍛鍊邏輯 清單體快速輸出:   在這個注意力短缺，新知識層出不窮的互聯網時代，清單體寫作具有條理清晰、簡單易看、乾貨十足的特點，可以極大地減少讀者的閱讀壓力。 運用清單體寫作，可以快速吸收一本書的精華內容並且快速輸出，即使是面對一本不太對胃口的書，也能運用清單體寫作榨出它極少的好處。 掌握清單體的寫法，對我們好處極大，下面闡述一下清單體寫作的一些技巧。  一段三行強操作性:   文字簡潔，分行羅列清單體講究把複雜的道理簡單說，能用兩個字表達的意思，就不要用5個字。 所以清單體寫作，每句話不要太長，寫完後要多讀幾遍，反復修改，調整或刪除累贅的話。還有要善用空行，把文字分段。 讀者對冗長的文字很容易失卻耐心，把每段話限制在三行以內。標準的清單體格式是，用500~800字，輸出10條清單。  編輯鍛鍊邏輯:   注重邏輯，講究實用。清單體起到提醒知識點作用，一定要清晰明瞭，操作性強。 每條清單體不是簡單的羅列，各條清單體間都有其內在的聯繫。或是層層遞進、或是不同視角、或是按照現象原因方法劃分等。 選好要闡述的清單後，要思考，把他們按照什麼樣的方式去闡述，更容易讓人記住?可以運用思維導圖，對清單進行梳理，從而更有條理地闡述。 還有寫清單體的閱讀對象除了自己，還有別人。要考慮別人能不能看懂，對他們有沒有幫助？自己日後復習又能不能看懂？  每日文章: 以清單體草稿寫作, 以文章解答讀者問題 作為寫作草稿的清單體:   我們可以在自己擅長的領域多花時間做積累，積累能夠寫清單的話題，有時間就蒐集整理素材，存入素材庫。 等到需要寫的時候，就把這些清單拿出來，也就不愁斷更了。 清單體比較適合分享知識類內容的文章，先確定大概的主題，然後廣泛搜索類似的網絡素材，並做好排序，就可以完成一篇清單體文章。 清單體相對好寫，關鍵是清單蒐集的質量要高。清單體一般最少湊足10條，但如果內容太多，就要捨得刪減，留下最精彩的。 最好的方式是找到專屬寫作主題，透過寫作主題反覆練習，戰勝自己的懶惰。  為讀者提供解答:   讀者愛看清單體，重點在於能一次看到多項介紹、比較，省去他花時間爬文，而且數量多，容易激起人性中，害怕錯過的特性，通常會有不錯的點閱。 寫出專屬你的清單體 清單體因為是以資料整理為主，導致相同主題能寫的資料有限，而在你之前，可能已經有很多人寫過，要和其他筆者做出差異，建議做足競爭者分析的功夫。 瞭解對方哪塊的資訊不足，而你能補充哪些資訊，替讀者解決問題。 重點就是瞭解讀者需要哪些資訊，幫助他們解決問題。  後記  到此我們提煉了與清單體相關的四個角度: 結構寫作, 知識分享, 知識輸出, 每日文章. 道與術皆有, 寫文章就能刺激自己具體化累積的知識, 留下數位足跡. 累積夠多的輸出後, 會產生湧現現象, 發展出更新的角度與觀點, 醍醐灌頂, 找到更好的知識模型.\n  自我反思, 今天已經是每日一篇文章的第七天. 的確, 現在看到各種資訊都會有意識地先整理成清單體, 累積夠多的知識點以後, 再以文章的形式輸出. 在輸出的過程, 提煉自己的邏輯組織, 總結小標題的能力. 這類的能力稱為「編輯能力」, 而世界上那麼多存在的知識, 要靠自己精選組織各種資訊, 成為文本, 才可以讓未來的自己回顧, 往更深層的理解前進. 持續向上, 共勉之！\n  2022.01.05. 紫蕊 於 西拉法葉, 印第安納, 美國.\n","date":"2022-01-05","img":"","permalink":"https://laplus3667.github.io/zh-tw/posts/mur007%E6%B8%85%E5%96%AE%E9%AB%94/","series":["每日文章"],"tags":[],"title":"MUR007 清單體的四個角度"},{"categories":["可信任的AI"],"content":"差分隱私尋根  紫式晦澀每日一篇文章第6天\n  前言   今天是2022年第4天, 第一週的第一個週二. 今天來思考差分隱私最基礎的定義.\n  今天的素材是Cynthia Dwork與Aaron Roth的The Algorithmic Foundations of Differential Privacy 的第二章所節選的材料.\n  差分隱私故事: 背景, 期望, 隱私洩露  差分隱私背景: 保護隱私的數據分析問題由來已久，橫跨多個學科。隨著關於個人的電子數據變得越來越詳細，以及技術使這些數據的收集和整理變得越來越強大，對一個強大的、有意義的、數學上嚴格的隱私定義的需求也在增加，同時也需要一個滿足這個定義的計算豐富的算法(a robust, meaningful, and mathematically rigorous definition of privacy, together with a computationally rich class of algorithms)類別。差分隱私就是滿足這樣定義的一系列演算法。\n  對隱私保護的期望: ”差分隱私 \u0026ldquo;描述了數據持有者對數據主體做出的承諾。\u0026ldquo;如果允許你的數據被用於任何研究或分析，無論其他研究、數據集或信息來源如何，你都不會受到不利或其他的影響。\u0026rdquo; 在最好的情況下，不同的私有數據庫機制可以使機密數據廣泛用於準確的數據分析，而不需要依賴於數據清洗、數據使用協議、數據保護計劃或限制訪問。\n  回答太清楚, 隱私就洩漏: 儘管如此，數據的效用最終還是會被消耗掉：信息恢復的基本法則(Fundamental Law of Information Recovery )指出，對太多問題的過度準確的回答會以驚人的方式破壞隱私。差別隱私的算法研究的目標是盡可能推遲這種不可避免性。\n  差分隱私是一個定義，不是一種算法: 對於一個給定的計算任務$T$和一個給定的$\\varepsilon$值，將有許多差分隱私算法以$\\varepsilon$-差分隱私的方式實現$T$。有些算法會比其他算法有更好的準確性。當$\\varepsilon$較小時，為$T$找到一個高度精確的$\\varepsilon$-差分隱私算法可能是困難的，就像為一個特定的計算任務找到一個數值穩定的算法一樣困難。\n  形式化基礎元素-輸出值機率向量, 隨機演算法, 其差分隱私性質. 機率單純型: 裡面的每個$x$都代表著一個「機率向量」, 對應每個可能輸出值的機率.   Definition 2.1 (Probability Simplex). Given a discrete set $B$, the probability simplex over $B$, denoted $\\Delta(B)$ is defined to be: $$\\Delta(B)={x \\in \\mathbb{R}^{|B|}: x_{i} \\geq 0 \\text { for all } i \\text { and } \\sum_{i=1}^{|B|} x_{i}=1}$$\n 隨機演算法: 看作一個隨機映射, 對一個固定的輸入a, 有一定的概率輸出b. 這個機率向量被前面的機率單純型給描述.一般來說，一個具有域$A$和（離散）範圍$B$的隨機算法將與一個從$A$到$B$上的概率單線的映射有關，表示為$\\Delta(B)$ 。   Definition 2.2 (Randomized Algorithm). A randomized algorithm $\\mathcal{M}$ with domain $A$ and discrete range $B$ is associated with a mapping $M: A \\rightarrow \\Delta(B) .$ On input $a \\in A$, the algorithm $\\mathcal{M}$ outputs $\\mathcal{M}(a)=b$ with probability $(M(a))_{b}$ for each $b \\in B$. The probability space is over the coin flips of the algorithm $\\mathcal{M}$.\n 數據庫的長度: 我們將認為「數據庫$x$」是來自宇宙$\\mathcal{X}$的記錄集合。用直方圖來表示數據庫往往很方便：$x\\in\\mathbb{N}^{|\\mathcal{X}|}$，其中每個條目$x_{i}$代表數據庫$x$中$i\\in\\mathcal{X}$類型的元素數量。在這種表述中，兩個數據庫$x$和$y$之間距離的自然度量將是它們的$\\ell_{1}$距離。   $|x|{1}$是衡量數據庫$x$的大小（即它所包含的記錄數. $|x-y|{1}$是衡量$x$和$y$之間有多少記錄不同。\n 隨機算法的差分隱私性質: 我們現在準備正式定義差異化隱私。直觀上, 保證了隨機化算法, 在類似的輸入數據庫上, 輸出是相似的。   Definition 2.4 (Differential Privacy). A randomized algorithm $\\mathcal{M}$ with domain $\\mathbb{N}^{|\\mathcal{X}|}$ is $(\\varepsilon, \\delta)$-differentially private if for all $\\mathcal{S} \\subseteq \\operatorname{Range}(\\mathcal{M})$ and for all $x, y \\in \\mathbb{N}^{|\\mathcal{X}|}$ such that $|x-y|_{1} \\leq 1$ : $$ \\operatorname{Pr}[\\mathcal{M}(x) \\in \\mathcal{S}] \\leq \\exp (\\varepsilon) \\operatorname{Pr}[\\mathcal{M}(y) \\in \\mathcal{S}]+\\delta $$where the probability space is over the coin flips of the mechanism $\\mathcal{M}$. If $\\delta=0$, we say that $\\mathcal{M}$ is $\\varepsilon$-differentially private.\n  保護隱私失敗的機率$\\delta$:通常情況下，我們對$\\delta$的值感興趣，它小於數據庫規模的任何多項式的倒數。特別是，$\\delta$的值在$1 /|x|_{1}$的數量級上是非常危險的：它們允許通過公佈少數數據庫參與者的完整記錄來 \u0026ldquo;保護隱私\u0026rdquo;.\n  有沒有失敗機率, 解釋起來很不同:然而，即使$\\delta$可以忽略不計，在$(\\varepsilon, 0)$和$(\\varepsilon, \\delta)$差異性隱私之間也有理論上的區別。其中最主要的是相當於量化順序的轉換。前者的輸出會差不多, 但後者的輸出可以差很多\n   $(\\varepsilon, 0)$差分隱私確保，對於機制$\\mathcal{M}(x)$的每一次運行，觀察到的輸出（幾乎）同樣可能在每個相鄰的數據庫中同時被觀察到。 相反，$(\\varepsilon, \\delta)$差分隱私說，對於每一對相鄰的數據庫$x, y$，事後觀察到的值$\\mathcal{M}(x)$在數據庫為$x$時比在數據庫為$y$時產生的可能性要大得多或小得多，這是極其不可能的。 然而，給定一個輸出$x_i\\sim\\mathcal{M}(x)$，有可能找到一個數據庫$y$，使$x_i$在$y$上產生的可能性遠遠大於數據庫為$x$時的可能性。也就是說，$x_i$ 在$\\mathcal{M}(y)$分布中的質量可能大大高於它在$\\mathcal{M}(x)$分布中的質量。   這樣來說，$(\\varepsilon, \\delta)$差分隱私雖然保護隱私, 但也讓之後相關的機器學習任務很難做.\n 隱私損失: 控制隱私預算, 免疫後處理轉換 定義隱私損失: 關鍵量是 $$\\mathcal{L}_{\\mathcal{M}(x) | \\mathcal{M}(y)}^{(\\xi)}=\\ln \\left(\\frac{\\operatorname{Pr}[\\mathcal{M}(x)=\\xi]}{\\operatorname{Pr}[\\mathcal{M}(y)=\\xi]}\\right).$$ 我們把它稱為觀察$\\xi$所產生的隱私損失。   這種損失可能是正的（當一個事件在$x$下比在$y$下更可能發生），也可能是負的（當一個事件在$y$下比在$x$下更可能發生）。 正如我們在Lemma 3.17中看到的，$(\\varepsilon, \\delta)$差分隱私確保對於所有相鄰的$x, y$，隱私損失的絕對值將被$\\varepsilon$所約束，概率至少為$1-\\delta$。   這個定義是把$e^{\\epsilon}$的部分做了個轉換; 可否把這個想成policy的decision變化的程度? 但感覺與隱私沒什麼關係. 這個寫法的好處可以跟似然比接起來, 也難怪可以用假設檢定的框架來做.\n  差分隱私對後處理是免疫的: 數據分析員在沒有關於私人數據庫的額外知識的情況下，不能計算私人算法$\\mathcal{M}$的輸出的函數並使其減少差異性隱私。\n   也就是說，如果一個算法保護了個人的隱私，那麼數據分析員不能增加隱私損失, 無論是在正式定義下還是在任何直觀意義上。 從形式上看，與數據無關的「後處理映射$f$」與$(\\varepsilon, \\delta)-$差分隱私算法$\\mathcal{M}$的組合也是$(\\varepsilon, \\delta)$差分隱私。   也是這個特點, 讓隱私處理後的資料可以被公開做研究.\n 後記  到此我們看過了Cynthia Dwork與Aaron Roth的The Algorithmic Foundations of Differential Privacy 的第二章的節選內容. 在「說太清楚就隱私洩露」的事實下, 我們需要給隨機演算法增加「差分隱私」的性質, 以免惡意人士透過觀察隨機演算法的輸出值, 來還原特定的數據. 形式化框架下, 經過差分隱私處理後的數據, 在後處理下不會造成額外的隱私洩露. 對形式化的學術研究而言, 「隱私損失」會是重點分析目標.\n  至此, 對差分隱私又多瞭解了一點, 也可以理解其形式化細節會與似然比, 假設檢定等等技術有關係. 很多統計的結果都可以套上這層外衣. 之後可以多想想這些基礎的關聯.\n  2022.01.04. 紫蕊 於 西拉法葉, 印第安納, 美國.\n","date":"2022-01-04","img":"","permalink":"https://laplus3667.github.io/zh-tw/posts/mur006%E5%B7%AE%E5%88%86%E9%9A%B1%E7%A7%81%E5%B0%8B%E6%A0%B9/","series":["每日文章"],"tags":["差分隱私"],"title":"MUR006 差分隱私尋根"},{"categories":["合成數據","可信任的AI"],"content":"合成數據如何幫助基於機器學習的偵測詐欺?  紫式晦澀每日一篇文章第5天\n  前言   今天是2022年第3天, 第一週的第一個週一!今天來思考「合成數據(Synthetic Data)」是如何在金融科技領域中，幫助「詐欺偵測(Fraud Detection)」的任務.\n  今天的素材主要是從文章Follow the Trail: Machine Learning for Fraud Detection in Fintech Applications 節選提到合成數據的相關段落 .\n  合成數據用於詐欺偵測-檢測率, 訓練數據集來源  合成數據對詐欺偵測的效果: 本文章實驗了ML方法對欺詐檢測的貢獻, 分別利用真實數據集與「合成數據集」來訓練. 此文章討論了各種方法在「檢測率」的有效性. 此外, 分析了所選特徵對其性能的影響.\n  詐欺偵測的訓練數據集-Kaggle, ML Repository, Simulator:\n   A. 金融科技的詐欺檢測, 缺乏公開可用的測試數據. B. 來源一: Kaggle數據集 (括信用卡數據集[9]、銀行交易數據[10]和區塊鏈歷史數據[11]). C. 來源二: 已知的、稍舊的合成數據集可以在UC Irvine ML Repository中找到（例如，UC Irvine[12]） D. 來源三:模擬器(Simulator) BankSim[13]和PaySim[14]等模擬器被應用於解決這個問題。前者代表了一個基於代理的銀行支付模擬器，而後者則通過生成客戶和執行交易來模擬移動交易。  合成數據集範例 PaySim: 基於私人數據, 注入惡意行為, 產生合成數據 PaySim的模擬器:   A. 在4.2.2節中，將介紹一個使用名為PaySim的模擬器生成的合成數據集（PaySim數據集在下文中）。 B. PaySim使用私人數據集的匯總數據，生成一個類似於交易正常運行的合成數據集，並注入惡意行為，以便日後評估欺詐檢測方法的性能。 C. 這是通過在一個非洲國家的真實交易樣本基礎上模擬移動支付交易來實現的。原始數據是由一家跨國移動金融服務提供商提供的[104]。 D. 在這個特定的數據集中，代理商的欺詐行為旨在通過控制或客戶的賬戶來獲利，並試圖通過轉移到另一個賬戶來清空資金，然後從系統中套現。 E. 數據集詳情見表5。 Table 5. Synthetic Financial Datasets for Fraud Detection dataset overview.    Dataset name Synthetic Financial Datasets for Fraud Detection     Domain Financial Transactions   Url https://www.kaggle.com/ntnu-testimon/paysim1    Year (accessed on 30 November 2020)   Type 2015   Subset Synthetic data   Annotated PS_20174392719_1491204439457_log.csv   Unbalanced Yes   No. of entries Yes   Contamination rate 6,362,620   Time duration 0.129%   No. of features 1 month   List of features 11    step, type, amount, name0rig, oldbalance0rg,      定義PaySim: PaySim.   A. 一個移動貨幣支付模擬器 移動貨幣支付模擬案例研究是基於一個真實的公司，該公司開發了一個移動貨幣實施方案，為手機用戶提供了使用手機作為一種電子錢包在他們之間轉移資金的能力。 B.「任務」是開發一種能夠檢測出表明欺詐的可疑活動的方法。 C. 不幸的是，在我們研究的最初階段，這項服務只在演示模式下運行。這使我們無法收集任何可用於分析可能的檢測方法的數據。 D. PaySim的開發包括兩個階段。  D.a 在第一階段，我們模擬並實現了一個MABS，它使用了真實的移動支付服務的模式，並根據對真實系統開始運行時可能出現的情況的預測，生成了合成數據。 D.b在第二階段，我們獲得了該系統的財務交易日誌，並開發了一個新版本的模擬器，該模擬器使用匯總的交易數據來生成更類似於原始來源的財務信息。   E. Keywords [en]: multi-agent based simulation, fraud detection, retail fraud, synthetic data http://bth.diva-portal.org/smash/get/diva2:1085629/FULLTEXT03.pdf .  BankSim: 用於詐欺檢測研究的合成數據 BankSim:   A. 小節4.2.3 介紹的數據集是使用BankSim創建的，這是一個基於代理的銀行支付模擬器，基於西班牙一家銀行提供的匯總交易數據樣本。 B. 目標: 生成可用於欺詐檢測研究的合成數據。 C. 這個數據集結合了正常的支付和已知的欺詐特徵，不包含任何個人信息或任何其他交易的披露。 D. 數據集的詳情見表6。    Dataset name Synthetic data from a financial payment system     Domain Financial Transactions   Url https://www.kaggle.com/ntnu-testimon/banksim1    Year (accessed on 30 November 2020)   Type 2014   Subset Synthetic data   Annotated bs140513_032310.csv   Unbalanced Yes   No. of entries Yes   Contamination rate 594,643   Time duration 1.21%   No. of features 6 months   List of features 10   Subset step, customer, age, gender, zipcode0ri,   Annotated merchant, zipMerchant, category, amount, fraud   Unbalanced bsNET140513_032310.csv   No. of entries Yes   Contamination rate Yes   Time duration 594,643   No. of features 1.21%   List of features 6 months      Bank Transaction Data: 檢測欺詐交易和洗錢的合成數據 Bank Transaction Data:   A.Bank Transaction Data是一種分析工具，旨在檢測欺詐交易和洗錢。 B. 開發人員希望建立一個工具，可以使用IFSC代碼提取銀行名稱；通過系統獲取兩個不同賬戶在同一日期的借方和貸方的相同數量的交易以及匹配的敘述；並在敘述的基礎上對類似交易進行分類。 C. 數據集的細節見表7。    Dataset name Bank Transaction Data     Domain Financial Transactions   Url https://www.kaggle.com/apoorvwatsky/bank-    Year transaction-data (accessed on 30 November 2020)   Type 2017   Subset Synthetic data   Annotated bank.xlsx   Unbalanced No   No. of entries n//a   Contamination rate 116,201   Time duration n//a   No. of features 7 months    8   List of features Account No., Date, Transaction Details, Cheque    No. , Value Date, Withdrawal Amount, Deposit      結果與洞察: 合成數據集中, 特徵的可變性不夠高  Variability of features in a synthetically created dataset might not be on a high enough level.\n 合成數據集中, 特徵的可變性不夠高:   圖15中給出了被測試的集合方法的ROC曲線比較。 基於tpr和tnr的比較分析表明，對於一個給定的數據集，AdaBoost在測試方法中表現最好。 同時，可以注意到這三種測試方法的靈敏度和特異性都很高，幾乎為1，這表明合成的數據集中特徵的可變性可能還不夠高(variability of features in a synthetically created dataset might not be on a high enough level)。 還應該注意的是，在這個特定的數據集上，集合方法的表現優於離群點檢測方法。   結論與洞察: 利用集群方法, 執行基於合成數據的訓練, 會有更好的效果.  ensemble approaches significantly outperformed outlier detection methods on the two tested synthetic datasets\n 集成方法在合成數據集上表現較好   所進行的實驗結果證實了ML的好處。 首先，現有的ML算法成功地在複雜的數據集中檢測到了異常情況。 此外，實驗結果證實，ML方法可以通過支持增強欺詐檢測能力的方式，成功地為金融技術系統的安全做出貢獻。 此外，研究還發現，特徵工程和選擇會嚴重影響某些算法的性能，仔細選擇特徵可以提高整體性能並限制某些特徵的負面影響。 還應注意的是，集合方法對可變的特徵選擇情況保持了更穩健的性能，總體表現非常好，在大多數情況下比離群值檢測方法更好 集合方法在兩個測試的合成數據集（PaySim和BankSim）上的表現明顯優於離群值檢測方法 (ensemble approaches significantly outperformed outlier detection methods on the two tested synthetic datasets) 而在包含真實數據的測試數據集（CreditCard）上，這兩種方法的結果是相當的。  後記  到此我們看過了Follow the Trail: Machine Learning for Fraud Detection in Fintech Applications 文章中關於「合成數據」的段落與洞察。本文章指出(1) 公開用於訓練機器學習模型的合成數據集(PaySim 與 BankSim), 特徵的可變性可能不夠高, (2) 利用集群方法(Ensemble Method), 執行基於合成數據的訓練, 會有更好的效果.\n  這邊所謂的「合成數據」的邏輯, 似乎是加入惡意行為, 然後看使用的算法是否能夠成功抓到惡意行為. 惡意行為的「產生機制」可否用deep learning來做呢? 這樣的generative model, 生成帶有隱藏惡意行為的驗證資料(Validation dataset), 以此來審計(audit)系統中使用的機器學習算法. 這類似學校對TA做種族平等的培訓, 以避免TA在課堂上做出違反符合美國大學系統價值下認為的平等.\n  十分有趣, 之後需要多學習一些詐欺偵測的資料科學工程技術, 來進一步思考此文章給出對合成數據集的洞察. 持續精進, 共勉之！\n  2022.01.03. 紫蕊 於 西拉法葉, 印第安納, 美國.\n","date":"2022-01-03","img":"","permalink":"https://laplus3667.github.io/zh-tw/posts/mur005%E5%90%88%E6%88%90%E6%95%B8%E6%93%9A%E5%A6%82%E4%BD%95%E9%97%9C%E8%81%AF%E5%81%B5%E6%B8%AC%E8%A9%90%E6%AC%BA/","series":["每日文章"],"tags":["金融科技","詐欺偵測"],"title":"MUR005 合成數據如何幫助基於機器學習的偵測詐欺?"},{"categories":["寫作"],"content":"知識管理的五個角度  紫式晦澀每日一篇文章第4天\n  前言   今天是2022年第2天! 今天來整理之前對「知識管理」話題的一些筆記.\n  今天的素材主要是從得到APP上收集而來. 從五個訊息源頭做了15個點的筆記. 以下整理為關於知識管理的五個角度.\n  組織知識管理: 重要性, 難題與巧勁  組織知識管理的重要性: 管理學家彼得·德魯克反復強調，知識型組織中，知識是最重要的資源。「知識管理」關係著組織能不能持續、高質量地發展。\n  組織知識管理的難題:組織的智慧分散在不同部門、員工身上。想找文件只能做伸手要，想要學習過去的經驗只能當面問，沒有一個統一的入口能讓人高效地找到有用的知識.\n  組織知識管理的巧勁: 人和知識能不能有效匹配，要看知識是不是正好對應你要解決的問題，是不是足夠及時；還要看量，「少瞭解決不了問題，多了增加識別難度。」\n  個人知識管理：數據，資訊，底層規律  數據管理: 第一個是數據管理的維度。在這個維度上，我們所談論的知識管理更多是具體的「數據層面技巧」。比如，下載的文件怎麼保存？學到的知識點怎麼歸類？如何快速搜索文件？如何給文件貼標籤？怎樣整理文件夾？在哪裡找到合適的書單？等等。\n  這個部分年輕時我也犯過很多錯, 想要收集很大量的數據, 包括書本, 課程, 雜誌等等. 但現在一切都變得很方便以後, 反而是應該讓數據就留在他的出處, 而我們僅需要根據當下的需求去取回相對應的部分, 組織成能解決問題的知識即可.\n  資訊管理: 第二個是信息管理的維度。在這個維度上，我們關注的是怎樣更好地理解、消化和應用獲得的各個知識點。有很多非常有用的方法可以組織起來強化這一過程，比如：如何做讀書筆記？如何用思維導圖增強理解？學習中精讀和泛讀的區別、行動學習法、刻意練習等等。而能夠有效利用這些方法，也是一個學習者進階的標誌——能夠有效地把學到的知識用於解決問題。\n  這個部分有了Obsidian以後, 逐漸從note-taking轉化為note-making. 的確, 要將「數據, 文本」轉化成「資訊, 知識」需要倚靠各種框架來蒸餾出價值. 我們在學習的過程需要借助「語言的重複性」來增進理解, 但記憶的過程需要「知識的結構化」材能有效建立資訊之間的連結. 這個部分小小Sha的知識卡片書籍幫助很大, 持續master裡面的技藝.\n  底層邏輯管理: 第三個是底層規律的維度。在這個維度上，我們關心的不僅僅是具體的方法和技巧，更關心自己的認知深度：我們必須在大量具體知識積澱的基礎上，形成更宏觀和抽象的理解，在深層次上掌握普遍規律，從而將之前學到的繁雜的知識用一根線串起來，在具體知識之外找到新的答案，將有形化為無形，又將無形用於有形。\n  這個部分是30歲要更加要求自己的. 建立自己的知識體系已經簡單, 但如何「刻意驗證」來不斷升級自己知識體系的能力, 就要靠持續做各種不同的應用來累積與這個事件具體的經驗。做項目可以幫助我們累積這方面的能力！終身學習, 持續精進, 做時間的朋友！\n  知識管理三學派: 技術, 行為, 綜合  技術學派-知識本身: 技術學派認為知識管理就是對信息的管理，強調運用信息技術手段管理顯性知識。他們強調運用電子郵件、群件及其他工具從人、知識庫以及計算機網絡獲取「顯性知識」。許多學者，包括計算機專業人員，目前仍然在深化這方面的研究，諸如數據挖掘技術、人工智能技術、知識存儲與更新技術等。在知識管理未來的發展中，信息技術將會提供更多、更強有力的支持。在知識管理的實踐中人們已逐步達成如下共識：信息技術雖然重要，但只是知識管理成功實施的必要而非充分條件。\n  行為學派-知識擁有人: 該學派認為知識管理是對擁有知識的人（即知識工作者）的管理，他們重視對表現為人力資本和結構資本的「智力（知識）資本」的管理。比較關注知識管理與企業戰略、企業競爭優勢關係的研究，還關注組織間知識管理的研究。\n  綜合學派-人與知識並重: 該學派認為知識管理不僅要對信息和人進行管理，還要將信息和人連接起來進行管理；知識管理就是要將信息處理能力和人的創新能力相互結合，增強組織對環境的適應能力。該學派融合了信息技術及經濟學、管理學的相關知識，推動了技術學派和行為學派的相互交流、學習與融合。由於綜合學派能用較為系統、全面的觀點看待和實施知識管理，所以能很快被實踐者所接受。\n  知識管理方法: 產生, 分享, 管理  資訊化風潮: 受到 1990 年代的資訊化（Informatization），知識管理的觀念出現，成為企業或組織累積知識財富、創造更多競爭力的人文與技術具備的系統。如何深化「知識產生」的內涵、針對不同族群去做「知識分享」的設計，是「知識管理」當前與未來更重要的目標。\n  五步驟-產生與分享: 將知識透過「獲得、記錄、組織、存取與更新」，不斷「去由外而內的累積」以及「由內而外的優化」，助於企業及個人做出決策，因應環境的變遷。在這五個步驟的循環中，前面三步驟為「知識的產生」－強調如何使隱性的知識（最後一段會說明）方法化（methodology），後面兩步驟為「知識的分享」－強調讓受眾（員工、網路社群、大眾等等）容易瞭解、容易接受，並且容易感受到「成果」。如何深化「知識產生」的內涵、針對不同族群去做「知識分享」的設計，這兩大部分是「知識管理」當前與未來更重要的目標。\n   獲得\u0026ndash;\u0026gt;紀錄\u0026ndash;\u0026gt;組織\u0026ndash;\u0026gt;存取\u0026ndash;\u0026gt;更新\n 方法（methodology): 一種帶有約束性甚至強制性的模型規範，它會明確地告訴人們應該做什麼，不應該做什麼，什麼先做，什麼後做，怎樣才能事半功倍，取得最大的效益等。因此，方法往往是以規範、章程，條例，使得接受者能有共同的畫面去瞭解這個概念。  知識管理心法: 多元資訊渠道, 秉持心中之軸, 實踐輸出效應 多元資訊渠道: 積累關注不同信息渠道，去試一切錯。增加信息入口，是使人突破成長的最好辦法。常見的信息入口比如，閱讀經典書籍，互聯網信息資源等等，更難獲得的信息入口其實在人群中，也就是人際關係和貴人指路。 ​​​​不用擔心錯過什麼，有一天你會明白，關閉可能性 與 開拓可能性，同樣重要。   關閉可能性 與 開拓可能性，同樣重要。\n  秉持心中之軸: 你的個人憲法就是你一直秉持的信念、價值觀、思維方式，要經過深思熟慮，幾次修改，才能定案。從你最深刻的經歷、最難忘的故事中，回想你最刻骨銘心的事情，那其中包含你的人生哲學。原則是恆久不變的，你對原則的理解是會因為經歷而改變的，所以原則是歷久彌新的，是可以信賴的。\n  實踐輸出效應:去新的方法、思維，首先通過實踐輸出。比如說手帳方法具體體現了生活方式和工作方法，記錄反思在手帳上。第二層輸出是我實踐之後的復盤反思，總結成文章，寫成公眾號文章。我的公眾號是以個人成長、生活方式為核心。公眾號文章是電子生活+工作手帳。第三層輸出是跟進自己的行動、以及觀察生活中其他人的行為，調動我知識體系中的觀點、思維方式，去再一次更新我的認知框架和輸出效應。\n   工作方法\u0026ndash;\u0026gt; 復盤反思\u0026ndash;\u0026gt; 更新認知框架與輸出效應.\n 後記  到此我們看過了知識管理的五個面向; 對於個人或者組織, 都是需要想「數據, 資訊, 底層規律」三者是如何結合進工作流. 好的工具, 好的團隊, 促進知識的產生, 管理與分享. 長期而言, 知識是在實踐的過程中, 將自己的知識體系與外部的世界做主動驗證, 藉由試錯來高速迭代.\n  自我反思, 現在已經能藉由主動輸出, 來進行高強度的知識應用. 讓平時的瀏覽成為積累素材, 讓平時的休憩成為編輯文章的好時機. 材料累積久, 產生湧現效應, 便能有意想不到的體悟. 另外, 獲得\u0026ndash;\u0026gt;紀錄\u0026ndash;\u0026gt;組織\u0026ndash;\u0026gt;存取\u0026ndash;\u0026gt;更新這個知識管理的五步驟, 也不謀而合與每日文章輸出相同. 持之以恆, 共勉之！\n  2022.01.02. 紫蕊 於 西拉法葉, 印第安納, 美國.\n","date":"2022-01-02","img":"","permalink":"https://laplus3667.github.io/zh-tw/posts/mur004%E7%9F%A5%E8%AD%98%E7%AE%A1%E7%90%86%E7%9A%84%E4%BA%94%E5%80%8B%E8%A7%92%E5%BA%A6/","series":["每日文章"],"tags":[],"title":"MUR004 知識管理的五個角度"},{"categories":["可信任的AI"],"content":"拉普拉斯差分隱私機制的四個面向  紫式晦澀每日一篇文章第3天\n  前言   今天是2022年的第一天! 今天思考了許多關於差分隱私相關的問題. 今天針對最經典的差分隱私機制,「拉普拉斯差分隱私機制」, 來做文章思考.\n  今天的素材是Cynthia Dwork與Aaron Roth的The Algorithmic Foundations of Differential Privacy 的章節3.3, 以及維基百科關於Additive noise mechanism 的條目.\n  場景: 數據庫查詢  數據庫查詢: 問題起源於「數據庫查詢(Database queries)」: 當我們查詢數據庫, 獲得數值資料時, 算法會將數據庫映射為k個實數回傳. 這個映射寫作$$f:\\text{數據庫}\\mapsto \\text{k個實數}.$$\n  敏感性: 我們能多準確地完成這樣的查詢呢? 利用「敏感性」來妙術最壞情況下, 一個人的數據可以改變「查詢映射f」的程度。   不確定性之必要: 萬一上述的敏感性很劇烈, 那麼惡意攻擊者就可以透過比較查詢結果, 來回推特定用戶的特定數據. 為了避免特定用戶的特定數據被還原出來, 增加不確定性是必要的.\n  直觀: 一個「查詢映射f」的靈敏度, 給出了我們必須對其輸出進行多大的擾動, 才能保護隱私, 的上限。 (The sensitivity of a function gives an upper bound on how much we must perturb its output to preserve privacy. )\n  方案: 增加拉普拉斯分佈為不確定性  拉普拉斯分佈: 拉普拉斯分布是指數分布的一個對稱版本。   拉普拉斯機制: 拉普拉斯機制將簡單地計算「查詢映射f」，並用來自拉普拉斯分布的噪聲來擾動每個坐標。 微調噪聲的規模將被校准為「查詢映射f的敏感性」（除以ε）。   拉普拉斯機制的隱私性質: 拉普拉斯機制保留了(ε,0)微分隱私。 處理前與處理後, 兩個查詢結果出現的機率, 不會差太多.\n  實例: 具體數據庫查詢任務  與機器學習的關係？\n  計算查詢: (Counting queries) 在數據庫中，有多少元素滿足特定\n  直方圖查詢: (Histogram queries) 將資料可能分佈的空間分割為單元格，查詢每個單元格中有多少數據庫元素\n  姓氏查詢: 從10,000個潛在名字的列表中計算出哪些名字在2010年人口普查的參與者中最常見. 是一種直方圖查詢.\n  差分隱私選取: (Differential private selection) 結果的空間是離散的，任務是產生一個 \u0026ldquo;最佳 \u0026ldquo;答案，在這種情況下，就是人口最多的直方圖單元。\n  最常見的病症: 在一組受訪者的醫療史中，哪種病症（大約）是最常見的，所以這組問題是，對於所考慮的每種病症，個人是否曾經接受過這種病症的診斷。\n  推廣: 加性噪音機制  推廣定義: 從預先確定的分布中, 添加受控的噪聲, 是設定「差分隱私機制」的一種方式。這種技術對於設計敏感數據上的實值函數的隱私機制很有用。常用於添加噪聲的分布包括拉普拉斯和高斯分布。\n  推廣敏感性: 令$\\mathcal{D}$為資料集; $f:\\mathcal{D} \\mapsto \\mathbb{R}$ 為查詢映射。則查詢映射的敏感性$\\Delta f$定義為 $$ \\Delta f = \\max |f(x)-f(y)|. $$ 這裡的最大值是在$\\mathcal{D}$中, 只差一個元素的一對資料集$x$和$y$。對於維度高的查詢映射函數, 通常在$\\ell_{1}$或$\\ell_{2}$下測量敏感性。\n  論證差分隱私性: 要論證該機制滿足$\\epsilon$差分隱私，需證明「輸出分布」在乘法意義上是封閉的。技巧是利用分佈本身的似然比.\n  後記  到此我們走完了一趟拉普拉斯機制相關的的基礎細節. 基本上, 問題的場景是對數據庫的各種查詢. 如果給準確的數值, 那惡意攻擊者有可能透過查詢結果來回推特定個體的某些數值. 因此, 根據查詢的特性本身針對資料變動的「敏感度」, 設計回傳的數值額外加上的不確定性, 就可以防止這類的惡意攻擊. 其中要量化隱私保護的程度, 就會用到拉普拉斯分佈的各種性質; 也不難想像「充分統計量」對應著「查詢映射」, 而「隱私保護查詢結果」對應著「不確定性部分的集中不等式」.\n  十分有趣, 而這類的工作在2021已經被延伸到各種機器學習模型的訓練上, 造成很多機器學習任務表現被影響甚巨. 因此, 藉由做「模型審計」相關的研究, 來評估「基於隱私保護資料所訓練的機器學習模型」, 是一個基礎必須做的工作. 合成數據, 在這個分野上, 是有什麼樣的直覺可以解決這個問題呢?\n  2022.01.01. 紫蕊 於 西拉法葉, 印第安納, 美國.\n","date":"2022-01-01","img":"","permalink":"https://laplus3667.github.io/zh-tw/posts/mur003%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%B7%AE%E5%88%86%E9%9A%B1%E7%A7%81%E6%A9%9F%E5%88%B6%E7%9A%84%E5%9B%9B%E5%80%8B%E9%9D%A2%E5%90%91/","series":["每日文章"],"tags":["差分隱私"],"title":"MUR003 拉普拉斯差分隱私機制的四個面向"},{"categories":["日本"],"content":"關於大晦日的五個知識點  紫式晦澀每日一篇文章第2天\n    今天是2021年的最後一天! 今天在Hololive六期生的出道後看了許多的vtuber. 其中日本文化裡一年的最後一天為「大晦日」. 一開始以為是悔改的意思, 但搜集資料後發現故事還不少, 很有意思.\n  今天的素材是在google上面搜尋「大晦日」, 將閱讀文章摘要三點累積而成. 共讀了5個文章, 總結出十五條細節. 下面總結出關於大晦日的五個知識點.\n  年末說法: 大晦日(おおみそか)，指的是每年新曆的12月31日。另外, 表達最後一天的日語還有「年末」和「年の暮れ(としのくれ)」。其中「末(matsu)」和「暮れ(kure)」表示「～的最後」的意思，所以兩者都表示「年末」、「1年的結束」。   神社文化: 神社在大晦日將舉行「大祓い」儀式，以淨化積累了一年的穢物。佛教則為了清除迷惑身心的108個煩惱，將敲響除夜（除夕夜）之鐘。人類有108個煩惱，每敲一次鐘就能消除一個煩惱，所以才敲響108次鐘。   晦日緣由: 在舊曆的晦日代表「每月的最後一天」，而一年的最後一天，也就是一年最後一個月的最後一天稱之為「大晦日」。「晦日」可追溯回中國，《公羊傳》中就有出現過「何以不日？晦日也。」的記載. 其中晦日指的是農曆中每月最後一日，當天幾乎看不到月亮. 晉代杜預對《左傳》的注釋就提到，「晦，月終，陰之盡。」在日本，晦字也有「月隠り（つきごもり）」之意，而「つごもり」正是日文「晦日」的其中一個讀法。 日文「晦日」的另一個讀法「みそか」，就是古文中「30日」的讀法〈如20日的讀音是はつか〉，而由於農曆月終不是29就是30，所以兩者稱呼都是「みそか」。  年神文化: 12月31日是日本人為了在「正月」迎接神靈, 而做各種準備的日子。在「正月」，日本人要迎接一年到頭守護家庭的神靈－「年神様」（年神，歲神），因此正月也是歡迎神靈之日。其中, 會於家門使用神靈休憩的靈木－「松」製作的松飾「門松」，立在家門左右。門松，還擔當著神靈的引路標誌。另外, 在玄關的門上面。還會裝飾「注連繩」，以迎接神靈。在神棚（かみだな：室內供奉神靈的架子），要上供「鏡餅」。   初夢文化: 初夢（はつゆめ）是「新年最初所作的夢」. 一般指在1月1日或1月2日夜晚所作的夢. 傳統日本人認為初夢可以用來占卜新的一年運勢. 特別的, 如果夢到了1.富士山（ふじさん）2.鷹（たか）3.茄子（なす）, 是非常吉利的象徵. ① 這三樣都是德川家康喜歡的東西 ② 富士山是日本第一的山、老鷹是最威猛的鳥類、茄子則是重貴的食物（容易腐壞不易保存 ) ③ 富士山是「無事（ぶじ）」的諧音、老鷹是「高（たかい）」的諧音、茄子是「事事順遂（事をなす）」的諧音.  今天是2021年的最後一天. 回顧過去一年成就許多, 也意識到自己更多的不足. 持續思考, 精進自己, 用輸出指導輸入, 用文章精煉思考. 新的一年, 持續學習語言, 程式, 做更落地的研究, 思考商業, 組織執行項目, 承擔更大的責任, 做一個大寫的人.\n  2021.12.31. 紫蕊 於 西拉法葉, 印第安納, 美國.\n","date":"2021-12-31","img":"","permalink":"https://laplus3667.github.io/zh-tw/posts/mur002%E9%97%9C%E6%96%BC%E5%A4%A7%E6%99%A6%E6%97%A5%E7%9A%84%E4%BA%94%E5%80%8B%E7%9F%A5%E8%AD%98%E9%BB%9E/","series":["每日文章"],"tags":[],"title":"MUR002 關於大晦日的五個知識點"},{"categories":["寫作"],"content":"每日寫文章的五個心法  紫式晦澀每日一篇文章第1天\n    新年新希望! 每天寫文章來增強自己的表達能力. 現在使用Obsidian與ipad可以很輕鬆收集素材; 接著使用github page來發表每日的文章.\n  今天素材收集是在google上面搜尋「每日寫文章」以後, 照讀到的文章總結出三個面相. 共讀了5個文章, 總結出十五條細節. 這個流程蠻不錯, 之後可以參考, 做淺淺的研究. (跟仔細讀paper的方法不同)\n  固定習慣: 目前的設定是每天晚上十點, 在床邊的書桌寫作. 在十一點左右將文章Po到網站上. 有想過可以將素材收集到臉書的粉絲專頁, 用mac系統的quick note等等. 晚上整理, 輸出, 成為以後寫書的材料.\n  格式魔法: 在開頭寫「紫式晦澀每日一篇文章第X天」, 蒐集要寫的素材所屬於的領域, 以及維持書寫輸出的自律習慣. 這個點很不錯, 讓努力能夠累積, 也有足夠的素材能夠當作更高級的文件的底料.\n  刻意輸入: 不要完美主義, 先完成30分的作品. 之後根據需求, 再把文件完善, 讓分數提高. 在消費媒體時, 也持續打字寫下想法, 這樣就有底稿, 可以執行模塊輸出. 利用「溝通黃金圈」或者「清單體」等等的寫作架構, 就可以文思泉湧, 讓思想具現化.\n  碎片分享: 文件都是改出來的. 當我們消費各種知識, 寫作能夠提升我們總結的能力. 這個過程稱為「知識生產」，而生產出來的產物則是「知識卡片」等等碎片化的知識(知識=資訊+脈絡+流程). 利用總結技巧, 模板化輸出, 是什麼為什麼怎麼做. 將成果天天分享於社群帳號; 累積夠多素材後還能整理成大的文章, 標準化寫作. 用粉絲專業寫平時靈感. 用專業帳號發個人品牌文章.\n  定性心流: 把寫文章步驟化, 例如: 關鍵字，架構，內文，插圖，制式內容，校正，內容說明，摘要，發文. 共九個步驟. 寫的時候不要回頭檢查文章, 只在校正的步驟做檢查重排; 當真的寫不出來, 就抽離, 做其他事情, 一但有了靈感就再繼續, 不要免強.\n  即將邁入三十歲, 感覺要從知識的消費者轉為生產者! 分享其實也是在為未來的自己做知識服務. 寫下來的東西對自己最有用. 文章的再修改也能讓未來的自己看見知識如何逐漸形成. 共勉之!\n  2021.12.30. 紫蕊 於 西拉法葉, 印第安納, 美國.\n","date":"2021-12-30","img":"","permalink":"https://laplus3667.github.io/zh-tw/posts/mur001%E6%AF%8F%E6%97%A5%E5%AF%AB%E6%96%87%E7%AB%A0%E7%9A%84%E4%BA%94%E5%80%8B%E5%BF%83%E6%B3%95/","series":["每日文章"],"tags":[],"title":"MUR001 每日寫文章的五個心法"},{"categories":["寫作"],"content":"","date":"2021-12-28","img":"","permalink":"https://laplus3667.github.io/zh-tw/posts/rdd001-%E7%A0%94%E7%A9%B6%E8%A8%AD%E8%A8%88%E7%B3%BB%E5%88%97%E5%B0%8E%E6%96%87/","series":["研究設計"],"tags":[],"title":"RDD001 研究設計系列導文"},{"categories":["寫作"],"content":"211223 思考豆腐塊文章的執行面  目的: 藉由寫豆腐塊文章來強化輸出. 讀者: 放在自己的blog上面. 原則: 一篇文章只講一個觀點. 這個觀點, 快的話應該是要從讀的東西輸出 執行: 理想上, 在製作[[AGM331 知識卡片 (Knowledge Card)]]的同時, 就可以加工成[[豆腐塊作文]], 發到網站上, 整理思想.\n目的: 藉由寫豆腐塊文章來強化輸出. 讀者: 放在自己的blog上面. 原則: 一篇文章只講一個觀點. 這個觀點, 快的話應該是要從讀的東西輸出 執行: 理想上, 在製作[[AGM331 知識卡片 (Knowledge Card)]]的同時, 就可以加工成[[豆腐塊作文]], 發到網站上, 整理思想.\n把部落格當作平常練手的豆腐塊區域 練技術, 要實際寫程式練手 練寫作, 用各種豆腐塊練手\n豆腐塊: 簡述一篇學術文章的每個第一段; 給個Profile 這個Profile應該是各種觀點, 與各種術語.\n 可以練手, 用Fintech 與 Synthetic Data的交集來看.\n  Example : Fintech 與 Synthetic Data的交集.  MDPI   關於「備忘」與「筆記」 我現在意識到, 要有意地去改變寫「備忘」與「筆記」的比例; 「備忘」是讀了一些東西的觀後感, 小總結; 「筆記」則是什麼都不看, 環繞自己某個問題寫. 前者要重視轉化「外在文本」為「自身知識儲備」, 後者要重視轉化「自身知識儲備」為「具體問題的解決過程」. 所以在網站上, 只能放「筆記」 在個人知識庫裡, 主要放「備忘」\n","date":"2021-12-23","img":"","permalink":"https://laplus3667.github.io/zh-tw/posts/art478-%E8%B1%86%E8%85%90%E5%A1%8A%E6%96%87%E7%AB%A0%E6%80%9D%E8%80%83/","series":["豆腐塊"],"tags":[],"title":"ART478 思考豆腐塊文章的執行面"},{"categories":[],"content":"這是第一篇文章\n思考一: 實踐寫作套路, 學習寫作工作總結   想要研究寫作的套路，早上看了一些關於文案寫作的書。但他們的性質跟我們平常知識生產的模式不太一樣。 在網路上寫部落格的原因是什麼? 我想是經營個人品牌。因為我自己都還沒有個人網站。 那為什麼要建立個人品牌呢因為在現在這個時代我們找工作的履歷不再只是一張紙, 而是一個網站可以表現我們過去幾年的工作。 這個有點像在寫工作總結，那怎麼寫好工作總結呢？我覺得這就是可以看得到App上面的課程。  流程圖原始碼  1graph LR 2\tT(實踐寫作套路); A(發表網路部落格); R(建立個人品牌); Act(強化工作總結技能) 3\tT--\u0026gt;A--\u0026gt;R--\u0026gt;Act 思考二: 邏輯流 邏輯流治天下\n","date":"2021-12-21","img":"","permalink":"https://laplus3667.github.io/zh-tw/posts/art001-guidance/","series":[],"tags":["邏輯流"],"title":"ART001 文章概覽"},{"categories":null,"content":"Written in Go, Hugo is an open source static site generator available under the Apache Licence 2.0. Hugo supports TOML, YAML and JSON data file types, Markdown and HTML content files and uses shortcodes to add rich content. Other notable features are taxonomies, multilingual mode, image processing, custom output formats, HTML/CSS/JS minification and support for Sass SCSS workflows.\nHugo makes use of a variety of open source projects including:\n https://github.com/yuin/goldmark  https://github.com/alecthomas/chroma  https://github.com/muesli/smartcrop  https://github.com/spf13/cobra  https://github.com/spf13/viper   Hugo is ideal for blogs, corporate websites, creative portfolios, online magazines, single page applications or even a website with thousands of pages.\nHugo is for people who want to hand code their own website without worrying about setting up complicated runtimes, dependencies and databases.\nWebsites built with Hugo are extremelly fast, secure and can be deployed anywhere including, AWS, GitHub Pages, Heroku, Netlify and any other hosting provider.\nLearn more and contribute on GitHub .\n","date":"2019-02-28","img":"","permalink":"https://laplus3667.github.io/zh-tw/about/","series":null,"tags":null,"title":"About"},{"categories":null,"content":"","date":"0001-01-01","img":"","permalink":"https://laplus3667.github.io/zh-tw/contact/","series":null,"tags":null,"title":"Contact Us"},{"categories":null,"content":"","date":"0001-01-01","img":"","permalink":"https://laplus3667.github.io/zh-tw/faq/","series":null,"tags":null,"title":"FAQs"},{"categories":null,"content":"","date":"0001-01-01","img":"","permalink":"https://laplus3667.github.io/zh-tw/offline/","series":null,"tags":null,"title":"Offline"}]